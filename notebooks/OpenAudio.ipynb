{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# OpenAudio S1 Mini - Text-to-Speech Examples\n",
    "\n",
    "This notebook demonstrates how to use the **OpenAudio S1 Mini** model for high-quality text-to-speech generation.\n",
    "\n",
    "## Model Features\n",
    "- **0.5B parameter** distilled model from OpenAudio S1\n",
    "- **13 languages**: English, Chinese, Japanese, German, French, Spanish, Korean, Arabic, Russian, Dutch, Italian, Polish, Portuguese\n",
    "- **Emotion support**: (angry), (sad), (excited), (whispering), (laughing), etc.\n",
    "- **High quality**: 0.011 WER and 0.005 CER on English evaluation\n",
    "- **Fast inference**: Real-time factor ~1:7 on RTX 4090\n",
    "\n",
    "## Prerequisites\n",
    "- Downloaded model files in `../openaudio-s1-mini/`\n",
    "- Fish Speech framework (we'll install/check this below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model found at: /home/alec/git/talker/tts_api/openaudio-s1-mini\n",
      "üìÅ Model files: [PosixPath('../openaudio-s1-mini/codec.pth'), PosixPath('../openaudio-s1-mini/model.pth')]\n",
      "‚úÖ Fish Speech found at: /home/alec/git/talker/tts_api/fish-speech\n",
      "üìå Added Fish Speech to Python path\n",
      "\n",
      "üîß Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Check if Fish Speech is available, if not, clone and setup\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if we have the model files\n",
    "model_path = Path(\"../openaudio-s1-mini\")\n",
    "if model_path.exists():\n",
    "    print(f\"‚úÖ Model found at: {model_path.resolve()}\")\n",
    "    print(f\"üìÅ Model files: {list(model_path.glob('*.pth'))}\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found. Please download it first.\")\n",
    "\n",
    "# Check for Fish Speech repository\n",
    "fish_speech_path = Path(\"../fish-speech\")\n",
    "if not fish_speech_path.exists():\n",
    "    print(\"üì• Cloning Fish Speech repository...\")\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\", \"https://github.com/fishaudio/fish-speech.git\", \n",
    "        str(fish_speech_path)\n",
    "    ], check=True)\n",
    "    print(\"‚úÖ Fish Speech cloned successfully\")\n",
    "else:\n",
    "    print(f\"‚úÖ Fish Speech found at: {fish_speech_path.resolve()}\")\n",
    "\n",
    "# Add fish-speech to Python path if not already there\n",
    "if str(fish_speech_path.resolve()) not in sys.path:\n",
    "    sys.path.insert(0, str(fish_speech_path.resolve()))\n",
    "    print(\"üìå Added Fish Speech to Python path\")\n",
    "\n",
    "print(\"\\nüîß Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Method 1: Using Fish Speech API Server\n",
    "\n",
    "This is the recommended approach - running a local HTTP API server that provides REST endpoints for TTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Fish Speech API Server...\n",
      "üìã Command: python -m tools.api_server --listen 127.0.0.1:8080 --llama-checkpoint-path /home/alec/git/talker/tts_api/openaudio-s1-mini --decoder-checkpoint-path /home/alec/git/talker/tts_api/openaudio-s1-mini/codec.pth --decoder-config-name modded_dac_vq\n",
      "‚è≥ Waiting for server to start...\n",
      "‚úÖ API Server is running!\n",
      "üåê Access the WebUI at: http://127.0.0.1:8080/\n",
      "üí° Uncomment the line above to start the API server\n",
      "üí° Or run it manually in terminal with the command shown above\n"
     ]
    }
   ],
   "source": [
    "# Start the Fish Speech API Server in the background\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "def start_api_server():\n",
    "    \"\"\"Start the Fish Speech API server\"\"\"\n",
    "    fish_speech_path = Path(\"../fish-speech\")\n",
    "    model_path = Path(\"../openaudio-s1-mini\")\n",
    "    \n",
    "    # Change to fish-speech directory\n",
    "    os.chdir(fish_speech_path)\n",
    "    \n",
    "    # Start the API server\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"tools.api_server\",\n",
    "        \"--listen\", \"127.0.0.1:8080\",\n",
    "        \"--llama-checkpoint-path\", str(model_path.resolve()),\n",
    "        \"--decoder-checkpoint-path\", str(model_path.resolve() / \"codec.pth\"),\n",
    "        \"--decoder-config-name\", \"modded_dac_vq\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Starting Fish Speech API Server...\")\n",
    "    print(f\"üìã Command: {' '.join(cmd)}\")\n",
    "    \n",
    "    # Start server in background\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    \n",
    "    # Wait for server to start\n",
    "    print(\"‚è≥ Waiting for server to start...\")\n",
    "    for i in range(30):  # Wait up to 30 seconds\n",
    "        try:\n",
    "            response = requests.get(\"http://127.0.0.1:8080/\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úÖ API Server is running!\")\n",
    "                print(\"üåê Access the WebUI at: http://127.0.0.1:8080/\")\n",
    "                return process\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            print(f\"   Waiting... ({i+1}/30)\")\n",
    "    \n",
    "    print(\"‚ùå Server failed to start within 30 seconds\")\n",
    "    return None\n",
    "\n",
    "# Change back to original directory after\n",
    "original_dir = os.getcwd()\n",
    "\n",
    "# Uncomment the line below to start the server\n",
    "server_process = start_api_server()\n",
    "\n",
    "print(\"üí° Uncomment the line above to start the API server\")\n",
    "print(\"üí° Or run it manually in terminal with the command shown above\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Generating speech for: 'Hello world! This is OpenAudio S1 Mini speaking.'\n",
      "‚ùå Error generating speech: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8080/api/tts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Uncomment the lines above to generate speech once the server is running\n",
      "üí° Make sure the API server is started first!\n"
     ]
    }
   ],
   "source": [
    "# Make TTS API calls to the running server\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def generate_speech(text, save_path=\"output.wav\", emotion=None):\n",
    "    \"\"\"\n",
    "    Generate speech using the Fish Speech API\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to convert to speech\n",
    "        save_path (str): Path to save the audio file\n",
    "        emotion (str): Optional emotion marker like \"(excited)\" or \"(whispering)\"\n",
    "    \n",
    "    Returns:\n",
    "        Audio: IPython Audio object for playback\n",
    "    \"\"\"\n",
    "    url = \"http://127.0.0.1:8080/api/tts\"\n",
    "    \n",
    "    # Add emotion markers if specified\n",
    "    if emotion:\n",
    "        text = f\"{emotion} {text}\"\n",
    "    \n",
    "    # API request payload\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"format\": \"wav\",\n",
    "        \"reference_id\": None,  # Let model choose voice randomly\n",
    "        \"reference_audio\": None,\n",
    "        \"reference_text\": None,\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"chunk_length\": 200,\n",
    "        \"top_p\": 0.7,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"temperature\": 0.7,\n",
    "        \"streaming\": False\n",
    "    }\n",
    "    \n",
    "    print(f\"üé§ Generating speech for: '{text}'\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the audio file\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"‚úÖ Audio saved to: {save_path}\")\n",
    "        \n",
    "        # Return Audio object for Jupyter playback\n",
    "        return Audio(save_path)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error generating speech: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (uncomment when server is running)\n",
    "audio = generate_speech(\"Hello world! This is OpenAudio S1 Mini speaking.\")\n",
    "display(audio)\n",
    "\n",
    "print(\"üí° Uncomment the lines above to generate speech once the server is running\")\n",
    "print(\"üí° Make sure the API server is started first!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Emotion and Tone Examples\n",
    "\n",
    "OpenAudio S1 supports various emotional, tone, and special markers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Generating emotion examples...\n",
      "\n",
      "üéØ excited_speech.wav\n",
      "   Text: (excited) Hello everyone! I'm so thrilled to be here today!\n",
      "\n",
      "üéØ whisper_speech.wav\n",
      "   Text: (whispering) This is a secret message just between us.\n",
      "\n",
      "üéØ angry_speech.wav\n",
      "   Text: (angry) I can't believe this happened again!\n",
      "\n",
      "üéØ sad_speech.wav\n",
      "   Text: (sad) I'm feeling quite melancholy today.\n",
      "\n",
      "üéØ laughing_speech.wav\n",
      "   Text: (laughing) Ha ha ha, that's absolutely hilarious!\n",
      "\n",
      "üéØ shouting_speech.wav\n",
      "   Text: (shouting) Can everyone hear me in the back?\n",
      "üåç Generating multilingual examples...\n",
      "\n",
      "üó£Ô∏è english.wav\n",
      "   Text: Hello, how are you today?\n",
      "\n",
      "üó£Ô∏è french.wav\n",
      "   Text: Bonjour, comment allez-vous?\n",
      "\n",
      "üó£Ô∏è spanish.wav\n",
      "   Text: Hola, ¬øc√≥mo est√°s hoy?\n",
      "\n",
      "üó£Ô∏è german.wav\n",
      "   Text: Guten Tag, wie geht es Ihnen?\n",
      "\n",
      "üó£Ô∏è japanese.wav\n",
      "   Text: „Åì„Çì„Å´„Å°„ÅØ„ÄÅ‰ªäÊó•„ÅØ„ÅÑ„Åã„Åå„Åß„Åô„ÅãÔºü\n",
      "\n",
      "üó£Ô∏è chinese.wav\n",
      "   Text: ‰Ω†Â•ΩÔºå‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü\n",
      "üí° Uncomment the function calls above to run the demos\n",
      "üí° Make sure to start the API server first!\n"
     ]
    }
   ],
   "source": [
    "# Demo different emotions and tones\n",
    "emotions_examples = [\n",
    "    (\"(excited) Hello everyone! I'm so thrilled to be here today!\", \"excited_speech.wav\"),\n",
    "    (\"(whispering) This is a secret message just between us.\", \"whisper_speech.wav\"),\n",
    "    (\"(angry) I can't believe this happened again!\", \"angry_speech.wav\"),\n",
    "    (\"(sad) I'm feeling quite melancholy today.\", \"sad_speech.wav\"),\n",
    "    (\"(laughing) Ha ha ha, that's absolutely hilarious!\", \"laughing_speech.wav\"),\n",
    "    (\"(shouting) Can everyone hear me in the back?\", \"shouting_speech.wav\"),\n",
    "]\n",
    "\n",
    "# Multilingual examples\n",
    "multilingual_examples = [\n",
    "    (\"Hello, how are you today?\", \"english.wav\"),\n",
    "    (\"Bonjour, comment allez-vous?\", \"french.wav\"),\n",
    "    (\"Hola, ¬øc√≥mo est√°s hoy?\", \"spanish.wav\"),\n",
    "    (\"Guten Tag, wie geht es Ihnen?\", \"german.wav\"),\n",
    "    (\"„Åì„Çì„Å´„Å°„ÅØ„ÄÅ‰ªäÊó•„ÅØ„ÅÑ„Åã„Åå„Åß„Åô„ÅãÔºü\", \"japanese.wav\"),\n",
    "    (\"‰Ω†Â•ΩÔºå‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü\", \"chinese.wav\"),\n",
    "]\n",
    "\n",
    "def demo_emotions():\n",
    "    \"\"\"Generate speech samples for different emotions\"\"\"\n",
    "    print(\"üé≠ Generating emotion examples...\")\n",
    "    \n",
    "    for text, filename in emotions_examples:\n",
    "        print(f\"\\nüéØ {filename}\")\n",
    "        # audio = generate_speech(text, filename)\n",
    "        # if audio: display(audio)\n",
    "        print(f\"   Text: {text}\")\n",
    "\n",
    "def demo_multilingual():\n",
    "    \"\"\"Generate speech samples for different languages\"\"\"\n",
    "    print(\"üåç Generating multilingual examples...\")\n",
    "    \n",
    "    for text, filename in multilingual_examples:\n",
    "        print(f\"\\nüó£Ô∏è {filename}\")\n",
    "        # audio = generate_speech(text, filename)\n",
    "        # if audio: display(audio)\n",
    "        print(f\"   Text: {text}\")\n",
    "\n",
    "# Run demos (uncomment when server is running)\n",
    "demo_emotions()\n",
    "demo_multilingual()\n",
    "\n",
    "print(\"üí° Uncomment the function calls above to run the demos\")\n",
    "print(\"üí° Make sure to start the API server first!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Voice Cloning with Reference Audio\n",
    "\n",
    "Use your own voice samples to clone voices with OpenAudio S1 Mini via the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Available voice references:\n",
      "  üìÅ dsp: 10 files\n",
      "    üéµ dsp_05.wav\n",
      "    üéµ dsp_02.wav\n",
      "    ... and 8 more\n",
      "  üìÅ batman: 4 files\n",
      "    üéµ batman_02.wav\n",
      "    üéµ batman_01.wav\n",
      "    ... and 2 more\n",
      "  üìÅ demo_1: 1 files\n",
      "    üéµ demo_speaker0.mp3\n",
      "  üìÅ biden: 5 files\n",
      "    üéµ biden_04.wav\n",
      "    üéµ biden_02.wav\n",
      "    ... and 3 more\n",
      "  üìÅ trump_cp: 11 files\n",
      "    üéµ 2.wav\n",
      "    üéµ 5.wav\n",
      "    ... and 9 more\n",
      "  üìÅ major: 21 files\n",
      "    üéµ major_12.wav\n",
      "    üéµ major_14.wav\n",
      "    ... and 19 more\n",
      "  üìÅ demo_3: 1 files\n",
      "    üéµ demo_speaker2.mp3\n",
      "  üìÅ demo_2: 1 files\n",
      "    üéµ demo_speaker1.mp3\n",
      "  üìÅ trump: 29 files\n",
      "    üéµ trump_29.wav\n",
      "    üéµ trump_19.wav\n",
      "    ... and 27 more\n",
      "  üìÅ loli: 6 files\n",
      "    üéµ loli_02.wav\n",
      "    üéµ loli_02_02.wav\n",
      "    ... and 4 more\n",
      "üí° Uncomment the example above to test voice cloning\n",
      "üí° Make sure you have reference audio files in ../data/voices/\n"
     ]
    }
   ],
   "source": [
    "# Voice cloning with reference audio using the API\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_speech_with_reference(text, reference_audio_path, reference_text, save_path=\"cloned_output.wav\"):\n",
    "    \"\"\"\n",
    "    Generate speech using reference audio for voice cloning via API\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to convert to speech\n",
    "        reference_audio_path (str): Path to reference audio file\n",
    "        reference_text (str): Text that corresponds to the reference audio\n",
    "        save_path (str): Path to save the generated audio\n",
    "    \n",
    "    Returns:\n",
    "        Audio: IPython Audio object for playback\n",
    "    \"\"\"\n",
    "    url = \"http://127.0.0.1:8080/api/tts\"\n",
    "    \n",
    "    # Read and encode reference audio\n",
    "    try:\n",
    "        with open(reference_audio_path, \"rb\") as f:\n",
    "            reference_audio_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Reference audio file not found: {reference_audio_path}\")\n",
    "        return None\n",
    "    \n",
    "    # API request payload with reference audio\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"format\": \"wav\",\n",
    "        \"reference_id\": None,\n",
    "        \"reference_audio\": reference_audio_data,\n",
    "        \"reference_text\": reference_text,\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"chunk_length\": 200,\n",
    "        \"top_p\": 0.7,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"temperature\": 0.7,\n",
    "        \"streaming\": False\n",
    "    }\n",
    "    \n",
    "    print(f\"üé§ Generating speech with voice cloning...\")\n",
    "    print(f\"üìù Text: '{text}'\")\n",
    "    print(f\"üéµ Reference: {reference_audio_path}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=120)  # Longer timeout for voice cloning\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the audio file\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"‚úÖ Cloned audio saved to: {save_path}\")\n",
    "        \n",
    "        # Return Audio object for Jupyter playback\n",
    "        from IPython.display import Audio\n",
    "        return Audio(save_path)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error generating cloned speech: {e}\")\n",
    "        return None\n",
    "\n",
    "def list_available_voices():\n",
    "    \"\"\"List available reference voices in the data/voices directory\"\"\"\n",
    "    voices_dir = Path(\"../data/voices\")\n",
    "    if not voices_dir.exists():\n",
    "        print(\"‚ùå No voices directory found\")\n",
    "        return []\n",
    "    \n",
    "    voices = []\n",
    "    for voice_dir in voices_dir.iterdir():\n",
    "        if voice_dir.is_dir():\n",
    "            audio_files = list(voice_dir.glob(\"*.mp3\")) + list(voice_dir.glob(\"*.wav\"))\n",
    "            if audio_files:\n",
    "                voices.append({\n",
    "                    \"name\": voice_dir.name,\n",
    "                    \"path\": str(voice_dir),\n",
    "                    \"audio_files\": [str(f) for f in audio_files]\n",
    "                })\n",
    "    \n",
    "    print(\"üé≠ Available voice references:\")\n",
    "    for voice in voices:\n",
    "        print(f\"  üìÅ {voice['name']}: {len(voice['audio_files'])} files\")\n",
    "        for audio_file in voice['audio_files'][:2]:  # Show first 2 files\n",
    "            print(f\"    üéµ {Path(audio_file).name}\")\n",
    "        if len(voice['audio_files']) > 2:\n",
    "            print(f\"    ... and {len(voice['audio_files']) - 2} more\")\n",
    "    \n",
    "    return voices\n",
    "\n",
    "# List available voices\n",
    "available_voices = list_available_voices()\n",
    "\n",
    "# Example voice cloning (uncomment when server is running and you have reference audio)\n",
    "# if available_voices:\n",
    "#     first_voice = available_voices[0]\n",
    "#     reference_path = first_voice['audio_files'][0]\n",
    "#     cloned_audio = generate_speech_with_reference(\n",
    "#         text=\"This is a test of voice cloning using the reference audio.\",\n",
    "#         reference_audio_path=reference_path,\n",
    "#         reference_text=\"This should be the text that matches the reference audio.\",\n",
    "#         save_path=\"voice_cloned_output.wav\"\n",
    "#     )\n",
    "#     if cloned_audio:\n",
    "#         display(cloned_audio)\n",
    "\n",
    "print(\"üí° Uncomment the example above to test voice cloning\")\n",
    "print(\"üí° Make sure you have reference audio files in ../data/voices/\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## API Integration Examples\n",
    "\n",
    "Here are some additional examples for integrating OpenAudio into your applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAudio server is running and ready!\n",
      "üí° Uncomment the examples above to test the TTS service wrapper\n"
     ]
    }
   ],
   "source": [
    "# Integration examples for using OpenAudio in applications\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "class OpenAudioTTSService:\n",
    "    \"\"\"A class to wrap OpenAudio TTS functionality for easy integration\"\"\"\n",
    "    \n",
    "    def __init__(self, api_url=\"http://127.0.0.1:8080\"):\n",
    "        self.api_url = api_url\n",
    "        self.tts_endpoint = f\"{api_url}/api/tts\"\n",
    "    \n",
    "    def is_server_running(self):\n",
    "        \"\"\"Check if the OpenAudio server is running\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.api_url, timeout=5)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def generate_speech(self, text, emotion=None, language=None, save_path=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate speech with optional emotion and language hints\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to convert to speech\n",
    "            emotion (str): Optional emotion marker like \"(excited)\" or \"(whispering)\"\n",
    "            language (str): Language hint (though OpenAudio auto-detects)\n",
    "            save_path (str): Optional path to save audio\n",
    "            **kwargs: Additional API parameters\n",
    "        \n",
    "        Returns:\n",
    "            bytes: Audio data or None if failed\n",
    "        \"\"\"\n",
    "        if not self.is_server_running():\n",
    "            print(\"‚ùå OpenAudio server is not running\")\n",
    "            return None\n",
    "        \n",
    "        # Add emotion markers if specified\n",
    "        if emotion:\n",
    "            text = f\"{emotion} {text}\"\n",
    "        \n",
    "        # Default payload\n",
    "        payload = {\n",
    "            \"text\": text,\n",
    "            \"format\": kwargs.get(\"format\", \"wav\"),\n",
    "            \"reference_id\": kwargs.get(\"reference_id\", None),\n",
    "            \"reference_audio\": kwargs.get(\"reference_audio\", None),\n",
    "            \"reference_text\": kwargs.get(\"reference_text\", None),\n",
    "            \"max_new_tokens\": kwargs.get(\"max_new_tokens\", 1024),\n",
    "            \"chunk_length\": kwargs.get(\"chunk_length\", 200),\n",
    "            \"top_p\": kwargs.get(\"top_p\", 0.7),\n",
    "            \"repetition_penalty\": kwargs.get(\"repetition_penalty\", 1.2),\n",
    "            \"temperature\": kwargs.get(\"temperature\", 0.7),\n",
    "            \"streaming\": kwargs.get(\"streaming\", False)\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.tts_endpoint, json=payload, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            audio_data = response.content\n",
    "            \n",
    "            # Save if path provided\n",
    "            if save_path:\n",
    "                with open(save_path, \"wb\") as f:\n",
    "                    f.write(audio_data)\n",
    "                print(f\"‚úÖ Audio saved to: {save_path}\")\n",
    "            \n",
    "            return audio_data\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå TTS generation failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def batch_generate(self, texts, emotion=None, output_dir=\"batch_output\"):\n",
    "        \"\"\"Generate multiple TTS files in batch\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        results = []\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            print(f\"üé§ Generating {i+1}/{len(texts)}: {text[:50]}...\")\n",
    "            output_path = Path(output_dir) / f\"speech_{i:03d}.wav\"\n",
    "            \n",
    "            audio_data = self.generate_speech(\n",
    "                text=text,\n",
    "                emotion=emotion,\n",
    "                save_path=str(output_path)\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"path\": str(output_path) if audio_data else None,\n",
    "                \"success\": audio_data is not None\n",
    "            })\n",
    "            \n",
    "            # Small delay to not overwhelm the server\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "tts_service = OpenAudioTTSService()\n",
    "\n",
    "# Test if server is running\n",
    "if tts_service.is_server_running():\n",
    "    print(\"‚úÖ OpenAudio server is running and ready!\")\n",
    "    \n",
    "    # Simple generation example\n",
    "    # audio_data = tts_service.generate_speech(\n",
    "    #     text=\"Hello, this is a test of the TTS service wrapper.\",\n",
    "    #     emotion=\"(confident)\",\n",
    "    #     save_path=\"service_test.wav\"\n",
    "    # )\n",
    "    \n",
    "    # Batch generation example\n",
    "    # sample_texts = [\n",
    "    #     \"Welcome to our application!\",\n",
    "    #     \"Please select an option from the menu.\",\n",
    "    #     \"Thank you for using our service.\",\n",
    "    #     \"Have a great day!\"\n",
    "    # ]\n",
    "    # results = tts_service.batch_generate(sample_texts, emotion=\"(friendly)\")\n",
    "    # print(f\"‚úÖ Generated {sum(1 for r in results if r['success'])}/{len(results)} files\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå OpenAudio server is not running. Please start it first.\")\n",
    "\n",
    "print(\"üí° Uncomment the examples above to test the TTS service wrapper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ OpenAudio S1 Mini Notebook Complete!\n",
      "\n",
      "üìã Summary of what we covered:\n",
      "  ‚úÖ Model download and setup\n",
      "  ‚úÖ API server startup\n",
      "  ‚úÖ Basic text-to-speech generation\n",
      "  ‚úÖ Emotion and tone control\n",
      "  ‚úÖ Multilingual support\n",
      "  ‚úÖ Voice cloning with reference audio\n",
      "  ‚úÖ Service wrapper for easy integration\n",
      "\n",
      "üöÄ Next steps:\n",
      "  1. Integrate the OpenAudioTTSService class into your applications\n",
      "  2. Experiment with different emotions and tones\n",
      "  3. Try voice cloning with your own reference audio\n",
      "  4. Optimize parameters (temperature, top_p) for your use case\n",
      "  5. Consider using streaming for real-time applications\n",
      "\n",
      "üîó Useful resources:\n",
      "  üìñ Fish Audio Documentation: https://speech.fish.audio/\n",
      "  ü§ó Model on Hugging Face: https://huggingface.co/fishaudio/openaudio-s1-mini\n",
      "  üí¨ Discord Community: https://discord.gg/fishaudio\n"
     ]
    }
   ],
   "source": [
    "# Clean up - stop the server if needed\n",
    "def cleanup_server():\n",
    "    \"\"\"Stop the OpenAudio server process\"\"\"\n",
    "    try:\n",
    "        if 'server_process' in globals() and server_process:\n",
    "            print(\"üõë Stopping OpenAudio server...\")\n",
    "            server_process.terminate()\n",
    "            server_process.wait(timeout=10)\n",
    "            print(\"‚úÖ Server stopped successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error stopping server: {e}\")\n",
    "\n",
    "# Summary and next steps\n",
    "print(\"üéâ OpenAudio S1 Mini Notebook Complete!\")\n",
    "print(\"\\nüìã Summary of what we covered:\")\n",
    "print(\"  ‚úÖ Model download and setup\")\n",
    "print(\"  ‚úÖ API server startup\")\n",
    "print(\"  ‚úÖ Basic text-to-speech generation\")\n",
    "print(\"  ‚úÖ Emotion and tone control\")\n",
    "print(\"  ‚úÖ Multilingual support\")\n",
    "print(\"  ‚úÖ Voice cloning with reference audio\")\n",
    "print(\"  ‚úÖ Service wrapper for easy integration\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"  1. Integrate the OpenAudioTTSService class into your applications\")\n",
    "print(\"  2. Experiment with different emotions and tones\")\n",
    "print(\"  3. Try voice cloning with your own reference audio\")\n",
    "print(\"  4. Optimize parameters (temperature, top_p) for your use case\")\n",
    "print(\"  5. Consider using streaming for real-time applications\")\n",
    "\n",
    "print(\"\\nüîó Useful resources:\")\n",
    "print(\"  üìñ Fish Audio Documentation: https://speech.fish.audio/\")\n",
    "print(\"  ü§ó Model on Hugging Face: https://huggingface.co/fishaudio/openaudio-s1-mini\")\n",
    "print(\"  üí¨ Discord Community: https://discord.gg/fishaudio\")\n",
    "\n",
    "# Uncomment to stop the server when done\n",
    "# cleanup_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
